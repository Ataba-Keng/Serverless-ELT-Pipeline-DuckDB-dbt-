# ğŸ¦† Serverless ELT Pipeline (DuckDB + dbt)

![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=flat&logo=python&logoColor=white)
![dbt](https://img.shields.io/badge/dbt-Core-FF694B?style=flat&logo=dbt&logoColor=white)
![DuckDB](https://img.shields.io/badge/DuckDB-In--Process-FFF000?style=flat&logo=duckdb&logoColor=black)

Ce projet est une dÃ©monstration d'une **Modern Data Stack ultra-lÃ©gÃ¨re (Serverless)**. 
Il implÃ©mente un pipeline ELT complet (Extract, Load, Transform) sans nÃ©cessiter d'infrastructure lourde (pas de Docker, pas de serveur Postgres), grÃ¢ce Ã  la puissance de **DuckDB**.

## ğŸ— Architecture

Contrairement aux stacks classiques (Airbyte/Postgres/Airflow) qui consomment beaucoup de RAM, cette architecture "Single Node" traite les donnÃ©es directement en processus local :

1.  **Ingestion (Python) :** GÃ©nÃ©ration et chargement de donnÃ©es brutes (Mock Data) vers DuckDB.
2.  **Storage (DuckDB) :** Base de donnÃ©es OLAP embarquÃ©e (fichier local).
3.  **Transformation (dbt) :** Nettoyage et modÃ©lisation des donnÃ©es via SQL modulaire.
4.  **Orchestration (Python) :** Un script pipeline gÃ¨re les dÃ©pendances et l'exÃ©cution sÃ©quentielle.

## ğŸ›  Tech Stack

* **Ingestion :** Python (`pandas`, `faker`)
* **Data Warehouse :** DuckDB
* **Transformation :** dbt (data build tool) - adapter `dbt-duckdb`
* **Orchestration :** Script Python natif

## ğŸš€ Installation & DÃ©marrage

### 1. Cloner le projet
```bash
git clone [https://github.com/ton-pseudo/lightweight-data-pipeline.git](https://github.com/ton-pseudo/lightweight-data-pipeline.git)
cd lightweight-data-pipeline
```
### 2. Configurer l'environnement
```bash
python3 -m venv venv
source venv/bin/activate  # Sur Windows : venv\Scripts\activate
pip install -r requirements.txt
```
### 3. Lancer le Pipeline
Le script pipeline.py exÃ©cute tout le flux (Ingestion -> dbt -> Tests) :
```bash
python pipeline.py
```
### 4. (Optionnel) Explorer les donnÃ©es

Pour voir le rÃ©sultat des transformations sans ouvrir d'outil externe :
```bash

python check_data.py
```
ğŸ“‚ Structure du Projet
Plaintext
```
.
â”œâ”€â”€ dbt_project/            # Projet dbt (ModÃ¨les SQL, config)
â”‚   â”œâ”€â”€ models/             # Logique mÃ©tier (Transformation)
â”‚   â””â”€â”€ dbt_project.yml     # Configuration dbt
â”œâ”€â”€ ingest.py               # Script d'ingestion (Extract & Load)
â”œâ”€â”€ pipeline.py             # Orchestrateur (Main Entrypoint)
â”œâ”€â”€ check_data.py           # Script de vÃ©rification/Visualisation
â”œâ”€â”€ profiles.yml            # Configuration de connexion DuckDB
â””â”€â”€ requirements.txt        # DÃ©pendances Python
```
ğŸ“ Auteur

Projet rÃ©alisÃ© par keng ATABA dans le cadre d'un portfolio Data Engineering. Objectif : DÃ©monstration d'optimisation de ressources et maÃ®trise de la Modern Data Stack.
